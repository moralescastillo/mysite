I"ï<p>MLflow is a platform to track experimentation, reproducibility, deployment of machine learning models. On the experimentation phase, mlflow facilitates the versioning of your models. It allows you to save not only the models but also metrics, parameters and datasets. For a quick introduction on mlflow, I found <a href="https://www.youtube.com/watch?v=vqigwhYyJ7M">this</a> tutorial and <a href="https://www.youtube.com/watch?v=OWJHHAtnAwY">that</a> tutorial to be very helpful.</p>

<p>Say that, to create a model, you standardized a data set using some scaler.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scaler = StandardScaler() 

scaler = scaler.fit(X_train) 
</code></pre></div></div>

<p>To make predictions on a new data set using this model, you will need not only the model but also the scaler. The scaler can be saved as a pickel object, using the package pickel.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#save the model locally using the package pickel 

import pickel 

pickel.dump(scaler, open('scaler.pkl', 'wb')) 

# save the scaler alongside the model under your mlflow experiment 

with mlflow.start_run(): 

	mlflow.sklearn.log_model(model_object, 'modelâ€™) 

	mlflow.log_artifact('scaler.pkl') 
	
run_id = '124bf7c43bdf4733a0a17c5d4435da71' 
</code></pre></div></div>

<p>On the databricks UI, a quick glance at the experimentâ€™s latest run shows you both objects.</p>

<p><img src="/asset/screenshot/2021-02-24-scaler-mlflow-databricks-img01.png" alt="" /></p>

<p>To retrieve the model, we use the function <code class="highlighter-rouge">load_model()</code>.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">#</span> <span class="nf">load</span> <span class="k">model</span> <span class="n">saved</span> <span class="n">under</span> <span class="nf">run</span> <span class="n">id</span> <span class="s1">'124bf7c43bdf4733a0a17c5d4435da71'</span>  

<span class="n">run_id</span> <span class="p">=</span> <span class="s1">'124bf7c43bdf4733a0a17c5d4435da71'</span> 

<span class="n">model_uri</span> <span class="p">=</span> <span class="s1">'runs:/'</span> <span class="p">+</span> <span class="n">run_id</span> <span class="p">+</span> <span class="s1">'/logisticRegr'</span> 

<span class="k">model</span> <span class="p">=</span> <span class="n">mlflow</span><span class="p">.</span><span class="n">sklearn</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_uri</span> <span class="p">=</span> <span class="n">model_uri</span><span class="p">)</span> 
</code></pre></div></div>

<p>To retrieve the scaler, we use the function download_artifacts(), as shown in the documentation.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>client = mlflow.tracking.MlflowClient() 

local_dir = "/tmp/artifact_downloads" 

if not os.path.exists(local_dir): 

	os.mkdir(local_dir) 
 

local_path = client.download_artifacts('124bf7c43bdf4733a0a17c5d4435da71', '', local_dir) 

scaler = open('/tmp/artifact_downloads/scaler.pkl', 'rb') 
</code></pre></div></div>

<p>The same procedure can be applied to retrieve any metric, parameter or data set.</p>
:ET